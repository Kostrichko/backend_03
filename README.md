# Отчет о разработке

## Быстрый запуск

Для быстрого запуска проекта выполнить:

```bash
cd django_aiogram
```
```bash
# 2. Создать .env файл
echo "BOT_TOKEN=ваш_токен_telegram_бота" > .env
echo "POSTGRES_DB=django_aiogram" >> .env
echo "POSTGRES_USER=postgres" >> .env
echo "POSTGRES_PASSWORD=postgres" >> .env
```
```bash
# 3. Запуск
docker compose up -d
```
```bash
# 4. Миграции
docker exec django_aiogram-web-1 python manage.py migrate
```
```bash
# 5. Открыть тг бота + /start
```

## Архитектурные решения

### 1. Telegram ID как первичный ключ

**Решение:** Использование `telegram_id` как primary key в модели User.

**Обоснование:**
- Telegram ID уникален и не меняется
- Упрощает логику идентификации пользователя
- Не требуется генерация собственных UUID
- Прямая связь между ботом и API без дополнительных маппингов


### 2. Лимиты на задачи и теги

**Решение:** Ограничение в 6 активных задач и 4 тега на пользователя (настраивается в settings).

**Обоснование:**
- Фокус на важных задачах (принцип ограниченного списка дел)
- Предотвращение злоупотреблений и перегрузки системы
- Упрощение UI бота (все задачи/теги влезают в одно сообщение)

**Настройка лимитов:**
```python
# config/settings.py
MAX_TAGS_PER_USER = 4
MAX_PENDING_TASKS_PER_USER = 6
```

### 3. Клавиатурный интерфейс

**Решение:** ReplyKeyboard с 6 основными кнопками вместо текстовых команд.

**Обоснование:**
- Интуитивнее для пользователей
- Меньше ошибок ввода
- Всегда видимое меню действий
- Соответствует современным UX паттернам мессенджеров

### 5. FSM для многошаговых операций

**Решение:** Finite State Machine для создания задач и тегов.

**Обоснование:**
- Четкая структура диалогов
- Валидация на каждом шаге
- Возможность отмены операции
- Хранение промежуточных данных в state

## Конфигурация

### Основные настройки

Проект использует Django settings для конфигурации. Основные параметры:

```python
# config/settings.py

# Лимиты пользователей
MAX_TAGS_PER_USER = 4                    # Максимум тегов на пользователя
MAX_PENDING_TASKS_PER_USER = 6           # Максимум активных задач

# API ключи
API_KEY = os.environ.get("API_KEY", "12345")  # Ключ для API аутентификации
BOT_TOKEN = os.environ.get("BOT_TOKEN")       # Токен Telegram бота

# База данных (PostgreSQL в продакшене)
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('POSTGRES_DB'),
        'USER': os.environ.get('POSTGRES_USER'),
        'PASSWORD': os.environ.get('POSTGRES_PASSWORD'),
        'HOST': 'postgres',
        'PORT': '5432',
    }
}

# Celery (Redis для очередей)
CELERY_BROKER_URL = "redis://redis:6379/0"
CELERY_RESULT_BACKEND = "redis://redis:6379/0"
```

### Переменные окружения

Создайте `.env` файл в корне проекта:

```bash
# .env
BOT_TOKEN=ваш_токен_telegram_бота
POSTGRES_DB=django_aiogram
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
API_KEY=ваш_секретный_ключ
```

## Трудности и их решение

### 1. Настройка Docker volumes

**Проблема:** При первом запуске Docker монтировал локальные папки поверх образа, что приводило к отсутствию установленных пакетов внутри контейнера. PostgreSQL адаптер `psycopg2` не находился, хотя был в `requirements.txt`.

**Решение:** Удалил volumes для кода в `docker-compose.yml`. Код теперь копируется в образ на этапе сборки. Это требует пересборки при изменениях, но устраняет проблемы с зависимостями.


### 2. Выбор между celery-beat и ETA

**Проблема:** Изначально реализовал периодическую задачу `check_due_tasks`, которая каждую минуту проверяла наступившие дедлайны. Это работало, но было неэффективно: worker постоянно "просыпался" и делал запросы к БД, даже если задач не было.

**Решение:** Переписал на использование Celery ETA. Теперь при создании задачи сразу планируется Celery task с параметром `eta=due_date`. Task выполняется ровно в нужное время, без опроса БД.

### 3. Health checks для PostgreSQL

**Проблема:** Django сервис и Celery worker пытались подключиться к PostgreSQL до того, как БД была готова принимать соединения. Это приводило к ошибкам при первом запуске через `docker compose up`.

**Решение:** Добавил health check для postgres в `docker-compose.yml`:
```yaml
healthcheck:
  test: ["CMD-READY", "pg_isready", "-U", "postgres"]
  interval: 5s
  timeout: 5s
  retries: 5
```
И добавил зависимость `depends_on.postgres.condition: service_healthy` для web и celery-worker.

### 4. Часовые пояса в Django и Python

**Проблема:** При парсинге `due_date` из строки получал "naive datetime", а Django ожидает "aware datetime" с timezone. Это вызывало предупреждения в логах.

**Решение:** Использую `timezone.now()` для текущего времени и `timezone.make_aware()` для парсинга дат из строк. В тестах использую `timezone.now() + timedelta()`.

## Тестирование

Разработан набор тестов покрывающий основной функционал:

### Запуск тестов

```bash
# Все тесты
docker exec django_aiogram-web-1 python manage.py test api --verbosity=2

# Конкретный класс
docker exec django_aiogram-web-1 python manage.py test api.tests.TagTestCase

# Конкретный тест
docker exec django_aiogram-web-1 python manage.py test api.tests.TaskTestCase.test_create_task
```

### Покрытие

- **TagTestCase**: Создание, дубликаты, лимиты, получение, удаление
- **TaskTestCase**: CRUD операции, архивация, множественные теги, лимиты
- **TaskNotificationTestCase**: Планирование уведомлений

Все тесты используют тестовую базу данных Django, которая создается и удаляется автоматически.

## Возможные улучшения

### Безопасность

1. **Аутентификация API**: Добавить токен-based аутентификацию для защиты REST эндпоинтов от несанкционированного доступа
2. **Rate limiting**: Ограничение частоты запросов к API для предотвращения DDoS атак
3. **Валидация входных данных**: Усиленная проверка всех пользовательских вводов на XSS и SQL-injection
4. **HTTPS**: Настройка SSL сертификатов для шифрования трафика между сервисами

### Функциональность

1. **Лимиты**: Возможность настройки лимитов задач/тегов
2. **Поиск по тегам**: Фильтрация задач по одному или нескольким тегам с поддержкой логических операторов
3. **Описание задач**: Добавление поля `description` для детального описания задачи
4. **Гибкая настройка времени**: Расширение опций уведомлений (не только фиксированные 1min, 2min, 5min, но и произвольное время, повторяющиеся уведомления)
5. **Повторяющиеся задачи**: Поддержка recurring tasks (ежедневно, еженедельно, ежемесячно)
6. **Приоритеты**: Уровни важности задач (low, medium, high, urgent) с сортировкой по приоритету

### Статистика и аналитика

1. **Дашборд продуктивности**: Визуализация выполненных задач по дням/неделям/месяцам
2. **Метрики выполнения**: Процент завершенных задач в срок, средний процент выполнения
3. **Трендовый анализ**: Графики активности, популярные теги, время выполнения задач
4. **Экспорт данных**: Выгрузка статистики в CSV/JSON для дальнейшего анализа

### Масштабируемость и отказоустойчивость

1. **Горизонтальное масштабирование**: Запуск нескольких инстансов celery-worker для обработки большого количества уведомлений
2. **DB replication**: Репликация PostgreSQL для распределения нагрузки на чтение
3. **Load balancer**: Nginx перед Django для распределения нагрузки между несколькими web инстансами
4. **Monitoring**: Prometheus + Grafana для мониторинга здоровья сервисов и метрик производительности

## Заключение

Система готова к развертыванию и дальнейшему масштабированию.
